#!/usr/bin/env python3
"""
ç™»å±±é“ãƒ‡ãƒ¼ã‚¿JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python commons/import_paths.py

Example:
    python commons/import_paths.py
"""

import argparse
import json
import os
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from pathlib import Path

from tqdm import tqdm

# Djangoã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
sys.path.insert(0, str(Path(__file__).parent.parent))
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "collectmap.settings")

import django

django.setup()

from django.db import transaction
from paths.models import Path as PathModel
from paths.models import PathGeometry, PathTag


def import_path_data(
    json_path: str, skip_existing: bool = True, batch_size: int = 100
) -> dict:
    """ç™»å±±é“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

    Args:
        json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹
        batch_size: ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆã®ã‚µã‚¤ã‚º

    Returns:
        ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®æƒ…å ±

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
        ValueError: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£
    """
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"File not found: {json_path}")

    # JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®š
    if isinstance(data, dict) and "elements" in data:
        # OpenStreetMap Overpass APIå½¢å¼: {"elements": [...]}
        paths_data = data["elements"]
    elif isinstance(data, list):
        # é…åˆ—
        paths_data = data
    else:
        raise ValueError(
            "Invalid JSON format: expected object with 'elements' key or array"
        )

    # wayã‚¿ã‚¤ãƒ—ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    # paths_data = [p for p in paths_data if p.get("type") == "way"]
    # print(f"  Total ways: {len(paths_data)}")

    # çµ±è¨ˆæƒ…å ±
    stats = {
        "total": len(paths_data),
        "created": 0,
        "skipped": 0,
        "errors": 0,
    }

    # å„ãƒ‘ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    # print("\nImporting paths...")
    # print(f"Batch size: {batch_size} (commits every {batch_size} items)")

    for i, path_data in enumerate(paths_data, 1):
        try:
            osm_id = path_data.get("id")
            path_type = path_data.get("type") or "way"
            geometry = path_data.get("geometry", [])

            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            if PathModel.objects.filter(osm_id=osm_id).exists():
                if skip_existing:
                    stats["skipped"] += 1
                    continue

            with transaction.atomic():
                # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                bounds = path_data.get("bounds", {})
                path = PathModel.objects.create(
                    osm_id=osm_id,
                    type=path_type,
                    minlat=bounds.get("minlat"),
                    minlon=bounds.get("minlon"),
                    maxlat=bounds.get("maxlat"),
                    maxlon=bounds.get("maxlon"),
                )

                # Geometriesã‚’è¿½åŠ 
                nodes = path_data.get("nodes", [])
                for idx, geom in enumerate(geometry):
                    PathGeometry.objects.create(
                        path=path,
                        node_id=nodes[idx] if idx < len(nodes) else 0,
                        lat=geom.get("lat"),
                        lon=geom.get("lon"),
                        sequence=idx,
                    )

                # Tagsã‚’è¿½åŠ 
                tags = path_data.get("tags", {})
                if tags:
                    PathTag.objects.create(
                        path=path,
                        highway=tags.get("highway"),
                        source=tags.get("source"),
                        difficulty=tags.get("difficulty"),
                        kuma=tags.get("kuma"),
                    )

                stats["created"] += 1
        except Exception as e:
            stats["errors"] += 1
            print(f"  Error: OSM ID {path_data.get('id', 'Unknown')} - {str(e)}")

        # ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆè¡¨ç¤º
        # if i % batch_size == 0:
        #     print(
        #         f"  â†’ Batch commit at {i} items (Created: {stats['created']}, Skipped: {stats['skipped']}, Errors: {stats['errors']})"
        #     )

    return stats


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    parser = argparse.ArgumentParser(description="ç™»å±±é“ãƒ‡ãƒ¼ã‚¿JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ")
    parser.add_argument(
        "--subdir",
        type=str,
        default="paths",
        help="ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: paths)",
    )
    parser.add_argument(
        "--workers",
        type=int,
        default=4,
        help="ä¸¦åˆ—å‡¦ç†ã®ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 4)",
    )
    args = parser.parse_args()

    data_folder = Path(__file__).parent.parent / "datas" / args.subdir

    if not data_folder.exists():
        print(f"âŒ Error: Data folder not found: {data_folder}")
        sys.exit(1)

    files = list(data_folder.glob("*.json"))

    files = [f for f in files if "ä¹å·" in f.name]

    if not files:
        print(f"âŒ Error: No JSON files found in {data_folder}")
        sys.exit(1)

    batch_size = 1000

    try:
        print("=" * 60)
        print("Path Data Import")
        print("=" * 60)
        print(f"Found {len(files)} JSON file(s)")

        total_stats = {
            "total": 0,
            "created": 0,
            "skipped": 0,
            "errors": 0,
        }

        with tqdm(
            total=len(files), desc="Processing JSON files", unit="file"
        ) as overall_pbar:
            with ThreadPoolExecutor(max_workers=args.workers) as executor:
                future_to_file = {
                    executor.submit(
                        import_path_data, str(json_path), True, batch_size
                    ): json_path
                    for json_path in files
                }

                for future in as_completed(future_to_file):
                    json_path = future_to_file[future]
                    try:
                        result = future.result()
                        print("\n" + "-" * 60)
                        print("ğŸ“Š File Import Summary")
                        print("-" * 60)
                        print(f"  File: {json_path.name}")
                        print(f"  Total: {result['total']}")
                        print(f"  âœ… Created: {result['created']}")
                        print(f"  â­ï¸  Skipped: {result['skipped']}")
                        print(f"  âŒ Errors: {result['errors']}")
                        print("-" * 60)

                        # ç´¯è¨ˆã‚’æ›´æ–°
                        total_stats["total"] += result["total"]
                        total_stats["created"] += result["created"]
                        total_stats["skipped"] += result["skipped"]
                        total_stats["errors"] += result["errors"]

                        if result["errors"] > 0:
                            print(
                                f"\nâš ï¸  Warning: {result['errors']} errors occurred during import"
                            )
                    except Exception as e:
                        print(f"\nâŒ Error processing file {json_path.name}: {e}")
                    finally:
                        overall_pbar.update(1)

        # æœ€çµ‚ã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 60)
        print("ğŸ“Š Total Import Summary")
        print("=" * 60)
        print(f"  Files: {len(files)}")
        print(f"  Total: {total_stats['total']}")
        print(f"  âœ… Created: {total_stats['created']}")
        print(f"  â­ï¸  Skipped: {total_stats['skipped']}")
        print(f"  âŒ Errors: {total_stats['errors']}")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
