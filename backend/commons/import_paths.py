#!/usr/bin/env python3
"""
ç™»å±±é“ãƒ‡ãƒ¼ã‚¿JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python commons/import_paths.py

Example:
    python commons/import_paths.py
"""

import json
import os
import sys
from pathlib import Path

from tqdm import tqdm
from utils import calculate_distance

# Djangoã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
sys.path.insert(0, str(Path(__file__).parent.parent))
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "collectmap.settings")

import django

django.setup()

from django.contrib.gis.geos import Polygon
from django.db.models.query import QuerySet

from paths.models import Path as PathModel
from paths.models import PathGeometry, PathGeometryOrder, PathTag


def merge_nodes_from_query_set(
    queryset: QuerySet[PathModel],
):
    threshold_distance_km = 0.1  # ãƒãƒ¼ãƒ‰ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹è·é›¢ã®é–¾å€¤ï¼ˆkmå˜ä½ï¼‰
    try:
        count = queryset.count()
        print(f"Starting merge_nodes_from_query_set with {count} paths")

        # QuerySetã‚’æ˜ç¤ºçš„ã«iteratorã§å–å¾—
        for path_a in tqdm(queryset.iterator(chunk_size=1000), total=count, desc="Merging nodes"):
            near_paths = Polygon.from_bbox(
                [path_a.minlon - 0.005, path_a.minlat - 0.005, path_a.maxlon + 0.005, path_a.maxlat + 0.005]
            )
            near_paths.srid = 4326
            nearby_queryset = queryset.filter(bbox__intersects=near_paths).exclude(id=path_a.id)

            for path_b in nearby_queryset:
                if path_a.id >= path_b.id:
                    continue
                # Through modelã‚’ä½¿ã£ã¦ç«¯ç‚¹ã‚’å–å¾—
                order_a0 = path_a.geometry_orders.select_related("geometry").order_by("sequence").first()
                order_a1 = path_a.geometry_orders.select_related("geometry").order_by("-sequence").first()
                order_b0 = path_b.geometry_orders.select_related("geometry").order_by("sequence").first()
                order_b1 = path_b.geometry_orders.select_related("geometry").order_by("-sequence").first()

                if not order_a0 or not order_a1 or not order_b0 or not order_b1:
                    continue  # geometriesãŒãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—

                node_a0, node_a1 = order_a0.geometry, order_a1.geometry
                node_b0, node_b1 = order_b0.geometry, order_b1.geometry

                dist_a0_b0 = calculate_distance(node_a0.lat, node_a0.lon, node_b0.lat, node_b0.lon)
                dist_a0_b1 = calculate_distance(node_a0.lat, node_a0.lon, node_b1.lat, node_b1.lon)
                dist_a1_b0 = calculate_distance(node_a1.lat, node_a1.lon, node_b0.lat, node_b0.lon)
                dist_a1_b1 = calculate_distance(node_a1.lat, node_a1.lon, node_b1.lat, node_b1.lon)

                def merge_nodes(node_a, path_a, node_b, path_b, order_b):
                    node_b_sequence = order_b.sequence

                    # node_bã®PathGeometryOrderã‚’å‰Šé™¤
                    order_b.delete()

                    # node_aã‚’åŒã˜sequenceã§path_bã«è¿½åŠ 
                    PathGeometryOrder.objects.create(path=path_b, geometry=node_a, sequence=node_b_sequence)

                    # node_bãŒä»–ã®Pathã«ä½¿ã‚ã‚Œã¦ã„ãªã‘ã‚Œã°å‰Šé™¤
                    if not node_b.path_orders.exists():
                        node_b.delete()

                    # ã‚¸ã‚ªãƒ¡ãƒˆãƒªãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°
                    path_a.update_geo_fields()
                    path_b.update_geo_fields()
                    path_a.save()
                    path_b.save()

                if dist_a0_b0 < threshold_distance_km:
                    merge_nodes(node_a0, path_a, node_b0, path_b, order_b0)
                elif dist_a0_b1 < threshold_distance_km:
                    merge_nodes(node_a0, path_a, node_b1, path_b, order_b1)
                elif dist_a1_b0 < threshold_distance_km:
                    merge_nodes(node_a1, path_a, node_b0, path_b, order_b0)
                elif dist_a1_b1 < threshold_distance_km:
                    merge_nodes(node_a1, path_a, node_b1, path_b, order_b1)
    except Exception as e:
        print(f"Error during merging nodes: {e}")
        import traceback

        traceback.print_exc()


def import_path_data(json_path: str, skip_existing: bool = True, batch_size: int = 100) -> dict:
    """ç™»å±±é“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

    Args:
        json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹
        batch_size: ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆã®ã‚µã‚¤ã‚º

    Returns:
        ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®æƒ…å ±

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
        ValueError: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"File not found: {json_path}")

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    with open(json_path, encoding="utf-8") as f:
        data = json.load(f)

    # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®šï¼ˆOverpass APIå½¢å¼ã¾ãŸã¯é…åˆ—å½¢å¼ï¼‰
    if isinstance(data, dict) and "elements" in data:
        paths_data = data["elements"]
    elif isinstance(data, list):
        paths_data = data
    else:
        raise ValueError("Invalid JSON format: expected object with 'elements' key or array")

    # çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
    stats = {
        "total": len(paths_data),
        "created": 0,
        "skipped": 0,
        "errors": 0,
    }

    # å„ãƒ‘ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
    with tqdm(paths_data, desc=f"Processing paths in {Path(json_path).name}", unit="path") as pbar:
        for i, path_data in enumerate(pbar, 1):
            try:
                # åŸºæœ¬æƒ…å ±ã‚’å–å¾—
                osm_id = path_data.get("id")
                path_type = path_data.get("type") or "way"
                geometry = path_data.get("geometry", [])

                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®ãƒã‚§ãƒƒã‚¯
                if PathModel.objects.filter(osm_id=osm_id).exists():
                    if skip_existing:
                        stats["skipped"] += 1
                        continue

                    # Pathãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
                bounds = path_data.get("bounds", {})
                path = PathModel.objects.create(
                    osm_id=osm_id,
                    type=path_type,
                    minlat=bounds.get("minlat"),
                    minlon=bounds.get("minlon"),
                    maxlat=bounds.get("maxlat"),
                    maxlon=bounds.get("maxlon"),
                )

                # ã‚¸ã‚ªãƒ¡ãƒˆãƒªæƒ…å ±ã‚’ä¿å­˜
                nodes = path_data.get("nodes", [])
                for idx, geom in enumerate(geometry):
                    path_geometry = PathGeometry.objects.create(
                        node_id=nodes[idx] if idx < len(nodes) else 0,
                        lat=geom.get("lat"),
                        lon=geom.get("lon"),
                    )
                    # Through modelã‚’ä½¿ã£ã¦Pathã¨PathGeometryã‚’é–¢é€£ä»˜ã‘
                    PathGeometryOrder.objects.create(path=path, geometry=path_geometry, sequence=idx)

                # ã‚¿ã‚°æƒ…å ±ã‚’ä¿å­˜
                tags = path_data.get("tags", {})
                if tags:
                    PathTag.objects.create(
                        path=path,
                        highway=tags.get("highway"),
                        source=tags.get("source"),
                        difficulty=tags.get("difficulty"),
                        kuma=tags.get("kuma"),
                    )

                # åœ°ç†æƒ…å ±ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ›´æ–°
                path.update_geo_fields()
                path.save(
                    update_fields=[
                        "route",
                        "bbox",
                        "minlon",
                        "minlat",
                        "maxlon",
                        "maxlat",
                    ]
                )

                stats["created"] += 1
            except Exception as e:
                stats["errors"] += 1
                pbar.write(f"âŒ Error importing OSM ID {path_data.get('id', 'Unknown')}: {str(e)}")

    return stats


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’è¨­å®š
    data_folder = Path(__file__).parent.parent / "datas" / "paths_merged"
    print(PathModel.objects.count())

    # ãƒ•ã‚©ãƒ«ãƒ€å­˜åœ¨ãƒã‚§ãƒƒã‚¯
    if not data_folder.exists():
        print(f"âŒ Error: Data folder not found: {data_folder}")
        sys.exit(1)

    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    files = list(data_folder.glob("*.json"))

    if not files:
        print(f"âŒ Error: No JSON files found in {data_folder}")
        sys.exit(1)

    batch_size = 1000

    try:
        # ã‚¤ãƒ³ãƒãƒ¼ãƒˆé–‹å§‹
        print("=" * 60)
        print("ğŸš€ Path Data Import Started")
        print(f"ğŸ“ Found {len(files)} JSON file(s) in {data_folder.name}")
        print("=" * 60)

        # çµ±è¨ˆæƒ…å ±ã®åˆæœŸåŒ–
        total_stats = {
            "total": 0,
            "created": 0,
            "skipped": 0,
            "errors": 0,
        }

        with tqdm(total=len(files), desc="Processing JSON files", unit="file") as overall_pbar:
            for json_path in files:
                try:
                    result = import_path_data(str(json_path), True, batch_size)

                    # çµ±è¨ˆã‚’ç´¯ç©
                    total_stats["total"] += result["total"]
                    total_stats["created"] += result["created"]
                    total_stats["skipped"] += result["skipped"]
                    total_stats["errors"] += result["errors"]

                    # ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è­¦å‘Šè¡¨ç¤º
                    if result["errors"] > 0:
                        print(f"\nâš ï¸  Warning: {result['errors']} error(s) in {json_path.name}")
                except Exception as e:
                    print(f"\nâŒ Fatal error processing {json_path.name}: {e}")
                finally:
                    overall_pbar.update(1)

        # æœ€çµ‚çµæœã®è¡¨ç¤º
        print("\n" + "=" * 60)
        print("âœ… Import Completed Successfully")
        print("ğŸ“Š Summary:")
        print(f"   Files processed: {len(files)}")
        print(f"   Total paths: {total_stats['total']}")
        print(f"   âœ… Created: {total_stats['created']}")
        print(f"   â­ï¸  Skipped: {total_stats['skipped']}")
        print(f"   âŒ Errors: {total_stats['errors']}")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ Fatal error occurred: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    try:
        print("\nğŸš§ Starting node merging process...")
        # merge_all_nodes()
        merge_nodes_from_query_set(PathModel.objects.all())

        print("âœ… Node merging completed.")
    except Exception as e:
        print(f"\nâŒ Error during node merging: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
