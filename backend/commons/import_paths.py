#!/usr/bin/env python3
"""
ç™»å±±é“ãƒ‡ãƒ¼ã‚¿JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python commons/import_paths.py

Example:
    python commons/import_paths.py
"""

import json
import os
import sys
from pathlib import Path

# Djangoã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
sys.path.insert(0, str(Path(__file__).parent.parent))
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "collectmap.settings")

import django

django.setup()

from django.db import transaction
from paths.models import Path as PathModel
from paths.models import PathGeometry, PathTag


def import_path_data(
    json_path: str, skip_existing: bool = True, batch_size: int = 100
) -> dict:
    """ç™»å±±é“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

    Args:
        json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹
        batch_size: ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆã®ã‚µã‚¤ã‚º

    Returns:
        ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®æƒ…å ±

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
        ValueError: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£
    """
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"File not found: {json_path}")

    # JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print(f"Reading JSON data from {json_path}...")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®š
    if isinstance(data, dict) and "elements" in data:
        # OpenStreetMap Overpass APIå½¢å¼: {"elements": [...]}
        paths_data = data["elements"]
        print(f"  Found 'elements' array with {len(paths_data)} path(s)")
    elif isinstance(data, list):
        # é…åˆ—
        paths_data = data
    else:
        raise ValueError(
            "Invalid JSON format: expected object with 'elements' key or array"
        )

    # wayã‚¿ã‚¤ãƒ—ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    paths_data = [p for p in paths_data if p.get("type") == "way"]
    print(f"  Total ways: {len(paths_data)}")

    # çµ±è¨ˆæƒ…å ±
    stats = {
        "total": len(paths_data),
        "created": 0,
        "skipped": 0,
        "errors": 0,
    }

    # å„ãƒ‘ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    print("\nImporting paths...")
    print(f"Batch size: {batch_size} (commits every {batch_size} items)")

    for i, path_data in enumerate(paths_data, 1):
        try:
            osm_id = path_data.get("id")
            path_type = path_data.get("type")
            geometry = path_data.get("geometry", [])

            # geometryã®é•·ã•ãƒã‚§ãƒƒã‚¯
            if len(geometry) < 20:
                if i % batch_size == 0 or i == 1:
                    print(
                        f"  [{i}/{len(paths_data)}] Skipped: OSM ID {osm_id} - less than 20 geometry points"
                    )
                stats["skipped"] += 1
                continue

            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            if PathModel.objects.filter(osm_id=osm_id).exists():
                if skip_existing:
                    if i % batch_size == 0 or i == 1:
                        print(
                            f"  [{i}/{len(paths_data)}] Skipped: OSM ID {osm_id} - already exists"
                        )
                    stats["skipped"] += 1
                    continue

            with transaction.atomic():
                # Pathã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                bounds = path_data.get("bounds", {})
                path = PathModel.objects.create(
                    osm_id=osm_id,
                    type=path_type,
                    minlat=bounds.get("minlat"),
                    minlon=bounds.get("minlon"),
                    maxlat=bounds.get("maxlat"),
                    maxlon=bounds.get("maxlon"),
                )

                # Geometriesã‚’è¿½åŠ 
                nodes = path_data.get("nodes", [])
                for idx, geom in enumerate(geometry):
                    PathGeometry.objects.create(
                        path=path,
                        node_id=nodes[idx] if idx < len(nodes) else 0,
                        lat=geom.get("lat"),
                        lon=geom.get("lon"),
                        sequence=idx,
                    )

                # Tagsã‚’è¿½åŠ 
                tags = path_data.get("tags", {})
                if tags:
                    PathTag.objects.create(
                        path=path,
                        highway=tags.get("highway"),
                        source=tags.get("source"),
                        difficulty=tags.get("difficulty"),
                        kuma=tags.get("kuma"),
                    )

                # 100ä»¶ã”ã¨ã¾ãŸã¯æœ€åˆã ã‘è¡¨ç¤º
                if i % batch_size == 0 or stats["created"] == 0:
                    highway = tags.get("highway", "unknown")
                    print(
                        f"  [{i}/{len(paths_data)}] Created: OSM ID {path.osm_id} (ID: {path.id}, highway: {highway})"
                    )

                stats["created"] += 1

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã¯æ¯å›è¡¨ç¤º
            print(
                f"  [{i}/{len(paths_data)}] Error: OSM ID {path_data.get('id', 'Unknown')} - {str(e)}"
            )
            stats["errors"] += 1

        # ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆè¡¨ç¤º
        if i % batch_size == 0:
            print(
                f"  â†’ Batch commit at {i} items (Created: {stats['created']}, Skipped: {stats['skipped']}, Errors: {stats['errors']})"
            )

    print(f"\n  Final progress: [{len(paths_data)}/{len(paths_data)}] Completed!")
    return stats


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    data_folder = Path(__file__).parent.parent / "datas" / "paths"

    if not data_folder.exists():
        print(f"âŒ Error: Data folder not found: {data_folder}")
        sys.exit(1)

    files = list(data_folder.glob("*.json"))

    if not files:
        print(f"âŒ Error: No JSON files found in {data_folder}")
        sys.exit(1)

    batch_size = 1000

    try:
        print("=" * 60)
        print("Path Data Import")
        print("=" * 60)
        print(f"Found {len(files)} JSON file(s)")

        total_stats = {
            "total": 0,
            "created": 0,
            "skipped": 0,
            "errors": 0,
        }

        for idx, json_path in enumerate(files, 1):
            print(f"\n[{idx}/{len(files)}] Importing from {json_path.name}...")
            result = import_path_data(
                str(json_path), skip_existing=True, batch_size=batch_size
            )

            print("\n" + "-" * 60)
            print("ğŸ“Š File Import Summary")
            print("-" * 60)
            print(f"  File: {json_path.name}")
            print(f"  Total: {result['total']}")
            print(f"  âœ… Created: {result['created']}")
            print(f"  â­ï¸  Skipped: {result['skipped']}")
            print(f"  âŒ Errors: {result['errors']}")
            print("-" * 60)

            # ç´¯è¨ˆã‚’æ›´æ–°
            total_stats["total"] += result["total"]
            total_stats["created"] += result["created"]
            total_stats["skipped"] += result["skipped"]
            total_stats["errors"] += result["errors"]

            if result["errors"] > 0:
                print(f"\nâš ï¸  Warning: {result['errors']} errors occurred during import")

        # æœ€çµ‚ã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 60)
        print("ğŸ“Š Total Import Summary")
        print("=" * 60)
        print(f"  Files: {len(files)}")
        print(f"  Total: {total_stats['total']}")
        print(f"  âœ… Created: {total_stats['created']}")
        print(f"  â­ï¸  Skipped: {total_stats['skipped']}")
        print(f"  âŒ Errors: {total_stats['errors']}")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
