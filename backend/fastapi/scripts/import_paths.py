#!/usr/bin/env python3
"""
ç™»å±±é“ãƒ‡ãƒ¼ã‚¿JSONã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Usage:
    python scripts/import_paths.py <json_file_path>

Example:
    python scripts/import_paths.py datas/sample_path.json
"""

import json
import os
import sys
from pathlib import Path

from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ï¼ˆãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‹ã‚‰ï¼‰
env_path = Path(__file__).parent.parent.parent / ".env"
load_dotenv(dotenv_path=env_path)

# FastAPIã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(str(Path(__file__).parent.parent))

from crud.path import create_path, get_path_by_osm_id
from database import SessionLocal
from schemas.path import PathImport
from sqlalchemy.orm import Session


def import_path_data(
    json_path: str, db: Session, skip_existing: bool = True, batch_size: int = 100
) -> dict:
    """ç™»å±±é“ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

    Args:
        json_path: JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        db: DBã‚»ãƒƒã‚·ãƒ§ãƒ³
        skip_existing: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ã‹
        batch_size: ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆã®ã‚µã‚¤ã‚º

    Returns:
        ã‚¤ãƒ³ãƒãƒ¼ãƒˆçµæœã®æƒ…å ±

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„
        ValueError: JSONãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒä¸æ­£
    """
    if not os.path.exists(json_path):
        raise FileNotFoundError(f"File not found: {json_path}")

    # JSONãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print(f"Reading JSON data from {json_path}...")
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®š
    if isinstance(data, dict) and "elements" in data:
        # OpenStreetMap Overpass APIå½¢å¼: {"elements": [...]}
        paths_data = data["elements"]
        print(f"  Found 'elements' array with {len(paths_data)} path(s)")
    elif isinstance(data, list):
        # é…åˆ—
        paths_data = data
    else:
        raise ValueError(
            "Invalid JSON format: expected object with 'elements' key or array"
        )

    # wayã‚¿ã‚¤ãƒ—ã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    paths_data = [p for p in paths_data]
    print(f"  Total ways: {len(paths_data)}")

    # çµ±è¨ˆæƒ…å ±
    stats = {
        "total": len(paths_data),
        "created": 0,
        "skipped": 0,
        "errors": 0,
    }

    # å„ãƒ‘ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
    print("\nImporting paths...")
    print(f"Batch size: {batch_size} (commits every {batch_size} items)")

    for i, path_data in enumerate(paths_data, 1):
        try:
            # Pydanticã§ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            path_import = PathImport(**path_data)

            # æ—¢å­˜ãƒã‚§ãƒƒã‚¯
            existing = get_path_by_osm_id(db, path_import.id)
            if existing:
                if skip_existing:
                    if i % batch_size == 0 or i == 1:  # 1000ä»¶ã”ã¨ã¾ãŸã¯æœ€åˆã ã‘è¡¨ç¤º
                        print(
                            f"  [{i}/{len(paths_data)}] Skipped: OSM ID {path_import.id} - already exists"
                        )
                    stats["skipped"] += 1
                    continue

            # boundsã‚’dictå½¢å¼ã«å¤‰æ›
            bounds_dict = None
            if path_import.bounds:
                bounds_dict = {
                    "minlat": path_import.bounds.minlat,
                    "minlon": path_import.bounds.minlon,
                    "maxlat": path_import.bounds.maxlat,
                    "maxlon": path_import.bounds.maxlon,
                }

            # geometryã‚’dictå½¢å¼ã«å¤‰æ›
            geometries_dict = [
                {"lat": g.lat, "lon": g.lon} for g in path_import.geometry
            ]

            if len(geometries_dict) < 20:
                if i % batch_size == 0 or i == 1:  # 100ä»¶ã”ã¨ã¾ãŸã¯æœ€åˆã ã‘è¡¨ç¤º
                    print(
                        f"  [{i}/{len(paths_data)}] Skipped: OSM ID {path_import.id} - less than 20 geometry points"
                    )
                stats["skipped"] += 1
                continue

            # DBã«ä¿å­˜
            created = create_path(
                db=db,
                osm_id=path_import.id,
                type=path_import.type,
                bounds=bounds_dict,
                nodes=path_import.nodes,
                geometries=geometries_dict,
                tags=path_import.tags,
            )

            # 100ä»¶ã”ã¨ã¾ãŸã¯æœ€åˆã ã‘è¡¨ç¤º
            if i % batch_size == 0 or stats["created"] == 0:
                highway = path_import.tags.get("highway", "unknown")
                print(
                    f"  [{i}/{len(paths_data)}] Created: OSM ID {created.osm_id} (ID: {created.id}, highway: {highway})"
                )

            stats["created"] += 1

        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã¯æ¯å›è¡¨ç¤º
            print(
                f"  [{i}/{len(paths_data)}] Error: OSM ID {path_data.get('id', 'Unknown')} - {str(e)}"
            )
            stats["errors"] += 1
            db.rollback()  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯

        # ãƒãƒƒãƒã‚³ãƒŸãƒƒãƒˆ
        if i % batch_size == 0:
            print(
                f"  â†’ Batch commit at {i} items (Created: {stats['created']}, Skipped: {stats['skipped']}, Errors: {stats['errors']})"
            )

    print(f"\n  Final progress: [{len(paths_data)}/{len(paths_data)}] Completed!")
    return stats


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    data_folder = Path(__file__).parent.parent.parent / "datas" / "paths"
    files = list(data_folder.glob("*.json"))

    batch_size = 1000

    # DBã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ä½œæˆ
    db = SessionLocal()

    try:
        print("=" * 60)
        print("Path Data Import")
        print("=" * 60)

        for i, json_path in enumerate(files, 1):
            print(f"\n[{i}/{len(files)}] Importing from {json_path}...")
            result = import_path_data(
                json_path, db, skip_existing=True, batch_size=batch_size
            )

            print("\n" + "=" * 60)
            print("ğŸ“Š Import Summary")
            print("=" * 60)
            print(f"  File: {json_path}")
            print(f"  Total: {result['total']}")
            print(f"  âœ… Created: {result['created']}")
            print(f"  â­ï¸  Skipped: {result['skipped']}")
            print(f"  âŒ Errors: {result['errors']}")
            print("=" * 60)

            if result["errors"] > 0:
                print(f"\nâš ï¸  Warning: {result['errors']} errors occurred during import")

    except Exception as e:
        print(f"\nâŒ Error occurred: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)

    finally:
        db.close()


if __name__ == "__main__":
    main()
