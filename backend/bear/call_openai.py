import os

from dotenv import load_dotenv
from openai import OpenAI
from pydantic import BaseModel, Field

load_dotenv()

OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")
if OPENAI_API_KEY is None:
    raise ValueError(
        "OPENAI_API_KEY is not set in environment variables."
    )  # üö® Raise an error if the API key is missing.

# --- 1. Initialize the LLM client ---
# Set the OpenAI API key.
client = OpenAI(api_key=OPENAI_API_KEY)


# --- 2. Define the output schema for the LLM (Pydantic) ---
# The LLM will generate JSON in this format.
class LLMAnalysisResult(BaseModel):
    is_sighting: bool = Field(
        description="Whether the article reports a specific bear sighting or incident."
    )
    prefecture: str | None = Field(None, description="Prefecture (e.g., Iwate).")
    city: str | None = Field(None, description="City or municipality (e.g., Morioka).")
    summary: str | None = Field(None, description="A concise summary of the situation.")


# --- 3. Analysis prompt ---
# Few-shot learning prompt with examples.
SYSTEM_PROMPT = f"""
„ÅÇ„Å™„Åü„ÅØ„Éã„É•„Éº„ÇπË®ò‰∫ã„ÇíÂàÜÊûê„Åô„Çã AI „Åß„ÅÇ„ÇãÔºé
Ë®ò‰∫ã„ÅÆ„Çø„Ç§„Éà„É´„Å®Ê¶ÇË¶Å„ÇíË™≠„ÅøÔºå„ÄåÂÖ∑‰ΩìÁöÑ„Å™„ÇØ„Éû„ÅÆÂá∫Ê≤°ÊÉÖÂ†±„Äç„Åã„Äå‰∏ÄËà¨ÁöÑ„Å™Ë©±È°åÔºàÊîøÁ≠ñ„Å™„Å©Ôºâ„Äç„Åã„ÇíÂàÜÈ°û„Åõ„ÇàÔºé
„Åï„Çâ„Å´Ôºå„ÄåÂÖ∑‰ΩìÁöÑ„Å™Âá∫Ê≤°ÊÉÖÂ†±„Äç„ÅÆÂ†¥Âêà„ÅÆ„ÅøÔºåÂ†¥ÊâÄ„Å®Ê¶ÇË¶Å„ÇíÊäΩÂá∫„ÅóÔºåË®ò‰∫ã„ÅÆÂÜÖÂÆπ„ÇíË¶ÅÁ¥Ñ„Åõ„ÇàÔºé

Ë¶ÅÁ¥Ñ„ÅØÊÉÖÂ†±„ÅÆÈÅé‰∏çË∂≥„Å™„ÅèÂàÜ„Åã„Çä„ÇÑ„Åô„ÅèÁ§∫„ÅóÔºå„Åß„Åô„Åæ„ÅôË™ø„Åß„ÅØ„Å™„ÅèÂ∏∏‰Ωì„ÅßË®òËø∞„Åô„Çã„Åì„Å®Ôºé
„Åæ„ÅüÔºå‰ª•‰∏ã„ÅÆ Pydantic „Çπ„Ç≠„Éº„Éû„Å´Âæì„Å£„Åü JSON ÂΩ¢Âºè„ÅßÂá∫Âäõ„Åô„Çã„Åì„Å®:
{LLMAnalysisResult.model_json_schema()}

---
(‰æã1)
ÂÖ•Âäõ:
- title: Â≤©ÊâãÈäÄË°åÊú¨Â∫ó„ÅÆÂú∞‰∏ãÈßêËªäÂ†¥ „ÇØ„Éû1È†≠„Åå‰æµÂÖ• ÊçïÁç≤
- description: 28Êó•ÂçàÂâçÔºåÁõõÂ≤°Â∏Ç„ÅÆ‰∏≠ÂøÉÈÉ®„Å´„ÅÇ„ÇãÂ≤©ÊâãÈäÄË°åÊú¨Â∫ó„ÅÆÂú∞‰∏ãÈßêËªäÂ†¥„Å´„ÇØ„Éû1È†≠„Åå...
Âá∫Âäõ:
{{
  "is_sighting": true,
  "prefecture": "Â≤©ÊâãÁúå",
  "city": "ÁõõÂ≤°Â∏Ç",
  "summary": "ÁõõÂ≤°Â∏Ç„ÅÆÂ≤©ÊâãÈäÄË°åÊú¨Â∫ó„ÅÆÂú∞‰∏ãÈßêËªäÂ†¥„Å´„ÇØ„Éû1È†≠„Åå‰æµÂÖ•„ÅóÔºåÊçïÁç≤„Åï„Çå„ÅüÔºé"
}}

---
(‰æã2)
ÂÖ•Âäõ:
- title: „Äê„É©„Ç§„Éñ‰∫àÂÆö„Äë„ÇØ„ÉûÈßÜÈô§ÊîØÊè¥ ÁßãÁî∞ÁúåÁü•‰∫ã„ÅåÈò≤Ë°õÁõ∏„Å´Á∑äÊÄ•Ë¶ÅÊúõ
- description: „ÇØ„Éû„Å´„Çà„Çã‰∫∫Ë∫´Ë¢´ÂÆ≥„ÅåÁßãÁî∞ÁúåÂÜÖ„ÅßÁõ∏Ê¨°„ÅÑ„Åß„ÅÑ„Çã„Åì„Å®„ÇíÂèó„ÅëÔºåÁßãÁî∞Áúå„ÅÆÈà¥Êú®Áü•‰∫ã„ÅØ...
Âá∫Âäõ:
{{
  "is_sighting": false,
  "prefecture": null,
  "city": null,
  "summary": null
}}
"""


# --- 4. Function to execute the LLM ---
def analyze_article_with_llm(title: str, description: str) -> LLMAnalysisResult | None:
    """
    Analyze an article using the LLM (GPT) and return structured data (Pydantic model).
    """
    if not description:
        description = title  # Use title if description is empty.

    user_prompt = f"""
    ÂÖ•Âäõ:
    - title: {title}
    - description: {description}
    Âá∫Âäõ:
    """

    try:
        response = client.chat.completions.create(
            model="gpt-5-nano",
            response_format={"type": "json_object"},
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_prompt},
            ],
        )

        response_json = response.choices[0].message.content
        print(f"üìù LLM analysis result (JSON): {response_json}")

        # Validate and parse the JSON using the Pydantic model.
        if response_json is not None:
            analysis_result = LLMAnalysisResult.model_validate_json(response_json)
        else:
            raise ValueError("Response JSON is None.")
        return analysis_result

    except Exception as e:
        print(f"‚ùå Error during LLM analysis: {e}")
        print(f"‚ö†Ô∏è Article that caused the error: {title}")
        return None
